#!/bin/bash

PROJECT_ID="your-project-id"
BQ_DATASET="gcs_metadata"
BQ_TABLE="bucket_info"
TEMP_FILE="bucket_info.csv"

# Create BigQuery dataset if not exists
bq --location=US mk -d --if_not_exists $BQ_DATASET

# Create table if not exists
bq query --use_legacy_sql=false --format=none \
"CREATE TABLE IF NOT EXISTS \`${PROJECT_ID}.${BQ_DATASET}.${BQ_TABLE}\` (
  bucket_name STRING,
  location STRING,
  storage_class STRING,
  versioning_enabled BOOL,
  time_created TIMESTAMP,
  size_bytes INT64
)"

# Remove old CSV file
rm -f $TEMP_FILE

# Get list of buckets
for BUCKET in $(gsutil ls -p $PROJECT_ID); do
  BUCKET_NAME=$(echo $BUCKET | sed 's/gs:\/\///;s/\/$//')

  # Get bucket metadata
  META=$(gsutil bucketinfo $BUCKET_NAME 2>/dev/null || gsutil ls -L -b gs://$BUCKET_NAME)

  LOCATION=$(echo "$META" | grep -m1 "Location constraint" | awk -F: '{print $2}' | xargs)
  STORAGE_CLASS=$(echo "$META" | grep -m1 "Storage class" | awk -F: '{print $2}' | xargs)
  VERSIONING=$(echo "$META" | grep -m1 "Versioning status" | awk -F: '{print $2}' | xargs)
  TIME_CREATED=$(echo "$META" | grep -m1 "Creation time" | sed 's/.*: //')

  [[ "$VERSIONING" == "Enabled" ]] && VERSIONING_ENABLED=true || VERSIONING_ENABLED=false

  # Get total size in bytes
  SIZE_BYTES=$(gsutil du -s gs://$BUCKET_NAME | awk '{print $1}')

  # Append to temp file
  echo "$BUCKET_NAME,$LOCATION,$STORAGE_CLASS,$VERSIONING_ENABLED,$TIME_CREATED,$SIZE_BYTES" >> $TEMP_FILE
done

# Load CSV into BigQuery
bq load --autodetect --replace --skip_leading_rows=0 \
  --source_format=CSV ${PROJECT_ID}:${BQ_DATASET}.${BQ_TABLE} $TEMP_FILE

echo "Upload complete. Data saved to BigQuery table ${BQ_DATASET}.${BQ_TABLE}."




__________
#!/bin/bash

PROJECT_ID="your-project-id"
BQ_DATASET="gcs_metadata"
BQ_TABLE="bucket_info"
TEMP_FILE="bucket_info.ndjson"

# Create BigQuery dataset if not exists
bq --location=US mk -d --if_not_exists $BQ_DATASET

# Create BigQuery table if not exists
bq query --use_legacy_sql=false --format=none \
"CREATE TABLE IF NOT EXISTS \`${PROJECT_ID}.${BQ_DATASET}.${BQ_TABLE}\` (
  meta_json JSON,
  size_bytes INT64,
  file_count INT64
)"

# Remove previous data file
rm -f $TEMP_FILE

# Loop through each bucket
for BUCKET in $(gsutil ls -p $PROJECT_ID); do
  BUCKET_NAME=$(echo $BUCKET | sed 's/gs:\/\///;s/\/$//')

  echo "Processing bucket: $BUCKET_NAME"

  # Get structured metadata
  META_JSON=$(gcloud storage buckets describe $BUCKET_NAME --project=$PROJECT_ID --format=json)

  # Get total size and object count
  BUCKET_STATS=$(gsutil ls -l -r gs://$BUCKET_NAME/** | grep -v "^TOTAL:" | awk 'BEGIN {total=0; count=0} /^[0-9]/ {total+=$1; count++} END {print total, count}')
  SIZE_BYTES=$(echo $BUCKET_STATS | awk '{print $1}')
  FILE_COUNT=$(echo $BUCKET_STATS | awk '{print $2}')

  # Create NDJSON line (JSON per line format for BigQuery)
  echo "{\"meta_json\": $META_JSON, \"size_bytes\": $SIZE_BYTES, \"file_count\": $FILE_COUNT}" >> $TEMP_FILE
done

# Load NDJSON into BigQuery
bq load --replace --source_format=NEWLINE_DELIMITED_JSON \
  "${PROJECT_ID}:${BQ_DATASET}.${BQ_TABLE}" $TEMP_FILE

echo "âœ… Upload complete. Bucket metadata and size info saved to BigQuery table ${BQ_DATASET}.${BQ_TABLE}."


COUNT=0
MAX_BUCKETS=10

for BUCKET in $(gsutil ls -p $PROJECT_ID); do
  ((COUNT++))
  if [ $COUNT -gt $MAX_BUCKETS ]; then
    break
  fi

  BUCKET_NAME=$(echo $BUCKET | sed 's/gs:\/\///;s/\/$//')

  echo "Processing bucket ($COUNT): $BUCKET_NAME"

  # Get structured metadata
  META_JSON=$(gcloud storage buckets describe $BUCKET_NAME --project=$PROJECT_ID --format=json)

  # Get total size and object count
  BUCKET_STATS=$(gsutil ls -l -r gs://$BUCKET_NAME/** | grep -v "^TOTAL:" | awk 'BEGIN {total=0; count=0} /^[0-9]/ {total+=$1; count++} END {print total, count}')
  SIZE_BYTES=$(echo $BUCKET_STATS | awk '{print $1}')
  FILE_COUNT=$(echo $BUCKET_STATS | awk '{print $2}')

  # Create NDJSON line
  echo "{\"meta_json\": $META_JSON, \"size_bytes\": $SIZE_BYTES, \"file_count\": $FILE_COUNT}" >> $TEMP_FILE
done


_____________<<<
META_JSON=$(gcloud storage buckets describe $BUCKET_NAME --project=$PROJECT_ID --format=json | tr -d '\n' | sed 's/  */ /g' | sed 's/"/\\"/g')


echo "{\"meta_json\": \"$META_JSON\", \"size_bytes\": $SIZE_BYTES, \"file_count\": $FILE_COUNT}" >> $TEMP_FILE
